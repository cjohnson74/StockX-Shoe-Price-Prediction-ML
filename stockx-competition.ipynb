{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y3/dlgpd0s57gx2x8t7lwlrczdm0000gn/T/ipykernel_42788/2051923040.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  shoes['Sale Price'] = shoes['Sale Price'].str.replace('[\\$\\,]|\\.\\d*', '').astype('float')\n",
      "/var/folders/y3/dlgpd0s57gx2x8t7lwlrczdm0000gn/T/ipykernel_42788/2051923040.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  shoes['Retail Price'] = shoes['Retail Price'].str.replace('[\\$\\,]|\\.\\d*', '').astype('float')\n"
     ]
    },
    {
     "data": {
      "text/plain": "  Order Date   Brand                                 Sneaker Name  Sale Price  \\\n0 2017-09-01   Yeezy         Adidas-Yeezy-Boost-350-Low-V2-Beluga      1097.0   \n1 2017-09-01   Yeezy  Adidas-Yeezy-Boost-350-V2-Core-Black-Copper       685.0   \n2 2017-09-01   Yeezy   Adidas-Yeezy-Boost-350-V2-Core-Black-Green       690.0   \n3 2017-09-01   Yeezy     Adidas-Yeezy-Boost-350-V2-Core-Black-Red      1075.0   \n\n   Retail Price Release Date  Shoe Size Buyer Region  Price Ratio  \n0         220.0   2016-09-24       11.0   California     4.986364  \n1         220.0   2016-11-23       11.0   California     3.113636  \n2         220.0   2016-11-23       11.0   California     3.136364  \n3         220.0   2016-11-23       11.5     Kentucky     4.886364  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order Date</th>\n      <th>Brand</th>\n      <th>Sneaker Name</th>\n      <th>Sale Price</th>\n      <th>Retail Price</th>\n      <th>Release Date</th>\n      <th>Shoe Size</th>\n      <th>Buyer Region</th>\n      <th>Price Ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas-Yeezy-Boost-350-Low-V2-Beluga</td>\n      <td>1097.0</td>\n      <td>220.0</td>\n      <td>2016-09-24</td>\n      <td>11.0</td>\n      <td>California</td>\n      <td>4.986364</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas-Yeezy-Boost-350-V2-Core-Black-Copper</td>\n      <td>685.0</td>\n      <td>220.0</td>\n      <td>2016-11-23</td>\n      <td>11.0</td>\n      <td>California</td>\n      <td>3.113636</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas-Yeezy-Boost-350-V2-Core-Black-Green</td>\n      <td>690.0</td>\n      <td>220.0</td>\n      <td>2016-11-23</td>\n      <td>11.0</td>\n      <td>California</td>\n      <td>3.136364</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas-Yeezy-Boost-350-V2-Core-Black-Red</td>\n      <td>1075.0</td>\n      <td>220.0</td>\n      <td>2016-11-23</td>\n      <td>11.5</td>\n      <td>Kentucky</td>\n      <td>4.886364</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "shoes = pd.read_csv('StockX-Data-Contest-2019.csv')\n",
    "\n",
    "# get rid of any dollar sign and commas in price and convert to float to divide\n",
    "shoes['Sale Price'] = shoes['Sale Price'].str.replace('[\\$\\,]|\\.\\d*', '').astype('float')\n",
    "shoes['Retail Price'] = shoes['Retail Price'].str.replace('[\\$\\,]|\\.\\d*', '').astype('float')\n",
    "\n",
    "# Create a \"Price Ratio\" column (SalePrice / RetailPrice = Price Ratio)\n",
    "shoes['Price Ratio'] = shoes['Sale Price'] / shoes['Retail Price']\n",
    "\n",
    "# Convert dates to pandas datetime\n",
    "shoes['Order Date'] = pd.to_datetime(shoes['Order Date'])\n",
    "shoes['Release Date'] = pd.to_datetime(shoes['Release Date'])\n",
    "\n",
    "shoes.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparing data\n",
    "TODO: Make sure all features are number based and between [0 - 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Order Date   Brand                                  Sneaker Name  \\\n",
      "86246     1/6/19   Yeezy  Adidas-Yeezy-Boost-350-V2-Semi-Frozen-Yellow   \n",
      "33080    6/30/18   Yeezy              adidas-Yeezy-Boost-350-V2-Butter   \n",
      "39356    7/22/18   Yeezy              adidas-Yeezy-Boost-350-V2-Butter   \n",
      "94586    1/31/19   Yeezy   adidas-Yeezy-Boost-350-V2-Static-Reflective   \n",
      "\n",
      "       Sale Price  Retail Price Release Date  Shoe Size   Buyer Region  Profit  \n",
      "86246         249           220     11/18/17        8.5       New York      29  \n",
      "33080         290           220      6/30/18       12.0        Florida      70  \n",
      "39356         288           220      6/30/18       14.0  West Virginia      68  \n",
      "94586         488           220     12/26/18        4.0         Oregon     268  \n",
      "Order Date                                           9/9/18\n",
      "Brand                                             Off-White\n",
      "Sneaker Name    adidas-Yeezy-Boost-350-V2-Static-Reflective\n",
      "Sale Price                                             4050\n",
      "Retail Price                                            250\n",
      "Release Date                                         9/9/17\n",
      "Shoe Size                                              17.0\n",
      "Buyer Region                                        Wyoming\n",
      "Profit                                                 3860\n",
      "dtype: object\n",
      "  Order Date   Brand                                   Sneaker Name  \\\n",
      "0     9/1/17   Yeezy           Adidas-Yeezy-Boost-350-Low-V2-Beluga   \n",
      "1     9/1/17   Yeezy    Adidas-Yeezy-Boost-350-V2-Core-Black-Copper   \n",
      "2     9/1/17   Yeezy     Adidas-Yeezy-Boost-350-V2-Core-Black-Green   \n",
      "3     9/1/17   Yeezy       Adidas-Yeezy-Boost-350-V2-Core-Black-Red   \n",
      "4     9/1/17   Yeezy  Adidas-Yeezy-Boost-350-V2-Core-Black-Red-2017   \n",
      "\n",
      "   Sale Price  Retail Price Release Date  Shoe Size  Buyer Region  Profit  \n",
      "0        1097           220      9/24/16       11.0    California     877  \n",
      "1         685           220     11/23/16       11.0    California     465  \n",
      "2         690           220     11/23/16       11.0    California     470  \n",
      "3        1075           220     11/23/16       11.5      Kentucky     855  \n",
      "4         828           220      2/11/17       11.0  Rhode Island     608  \n",
      "(69969, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation splits\n",
    "df_train = shoes.sample(frac=0.7, random_state=0)  # frac is the fraction of the data set to use\n",
    "df_valid = shoes.drop(df_train.index)  # drops (slices) the training data from shoes using the index (shoes - training = valid)\n",
    "print(df_train.head(4))\n",
    "\n",
    "# Scale to [0, 1]\n",
    "max_ = df_train.max(axis=0)\n",
    "print(max_)\n",
    "min_ = df_train.min(axis=0)\n",
    "# df_train = (df_train - min_) / (max_ - min_)\n",
    "# df_valid = (df_valid - min_) / (max_ - min_)\n",
    "\n",
    "# Split features and target\n",
    "X_train = df_train.drop('Sale Price', axis=1)\n",
    "X_valid = df_valid.drop('Sale Price', axis=1)\n",
    "y_train = df_train['Sale Price']\n",
    "y_valid = df_valid['Sale Price']\n",
    "\n",
    "print(shoes.head())\n",
    "print(X_train.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A three-layer network with over 1500 neurons.\n",
    "This network should be capable of learning fairly complex relationships in the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=512, activation='relu', input_shape=[7]),\n",
    "    layers.Dense(units=512, activation='relu'),\n",
    "    layers.Dense(units=512, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compile in the optimizer and loss function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Adam is a great general-purpose optimizer. :)\n",
    "# Adam is an SGD (Stochastic (Random) Gradient Descent) algo that has an adaptive learning rate (self-tuning) making it suitable for most problems.\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',  # MAE (Mean Absolute Error) abs(y_true - y_pred)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time to start training!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_valid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Keras feeds the optimizer 256 rows of the training data at a time\u001B[39;49;00m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 10 times all the way through the dataset\u001B[39;49;00m\n\u001B[1;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject20/venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/pythonProject20/venv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:103\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[0;34m(value, ctx, dtype)\u001B[0m\n\u001B[1;32m    101\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[1;32m    102\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=256, # Keras feeds the optimizer 256 rows of the training data at a time\n",
    "    epochs=10,  # 10 times all the way through the dataset\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
